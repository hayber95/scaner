<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document Scanner with Camera</title>
    <style>
        #video, #canvasOutput {
            width: 100%;
            height: auto;
        }
        #captureButton {
            display: block;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 16px;
        }
        #error {
            color: red;
            text-align: center;
        }
    </style>
</head>
<body>

<h2>Document Scanner</h2>
<!-- Video element for camera preview -->
<video id="video" autoplay playsinline></video>
<!-- Canvas to display the scanned image -->
<canvas id="canvasOutput"></canvas>
<!-- Button to capture the document -->
<button id="captureButton">Capture Document</button>
<p id="error"></p>

<script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
<script>
    async function openCamera() {
        try {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = stream;
            alert("Camera opened successfully");  // Confirmación de que la cámara se abrió
        } catch (error) {
            document.getElementById('error').textContent = "Error accessing the camera: " + error.message;
            alert("Error accessing the camera: " + error.message); // Error de acceso a la cámara
        }
    }

    function captureAndProcess() {
        alert("Starting document capture process");  // Comienza el proceso de captura

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvasOutput');
        const ctx = canvas.getContext('2d');
        const width = video.videoWidth;
        const height = video.videoHeight;

        canvas.width = width;
        canvas.height = height;

        ctx.drawImage(video, 0, 0, width, height);

        let src = cv.imread(canvas);
        let gray = new cv.Mat();
        let edges = new cv.Mat();
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();

        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        cv.Canny(gray, edges, 50, 150);

        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let maxArea = 0;
        let largestContour;
        for (let i = 0; i < contours.size(); i++) {
            let contour = contours.get(i);
            let area = cv.contourArea(contour, false);
            if (area > maxArea) {
                maxArea = area;
                largestContour = contour;
            }
        }

        let approx = new cv.Mat();
        if (largestContour) {
            cv.approxPolyDP(largestContour, approx, 0.02 * cv.arcLength(largestContour, true), true);

            if (approx.rows === 4) {
                alert("Document detected, starting perspective transformation");  // Documento detectado

                const points = [];
                for (let i = 0; i < 4; i++) {
                    points.push({
                        x: approx.data32S[i * 2],
                        y: approx.data32S[i * 2 + 1]
                    });
                }

                points.sort((a, b) => a.y - b.y);
                const topPoints = points.slice(0, 2).sort((a, b) => a.x - b.x);
                const bottomPoints = points.slice(2).sort((a, b) => a.x - b.x);
                const sortedPoints = [...topPoints, ...bottomPoints];

                const srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    sortedPoints[0].x, sortedPoints[0].y,
                    sortedPoints[1].x, sortedPoints[1].y,
                    sortedPoints[2].x, sortedPoints[2].y,
                    sortedPoints[3].x, sortedPoints[3].y
                ]);
                const dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    0, 0, width, 0, width, height, 0, height
                ]);

                const M = cv.getPerspectiveTransform(srcTri, dstTri);
                const dst = new cv.Mat();
                cv.warpPerspective(src, dst, M, new cv.Size(width, height));

                cv.imshow('canvasOutput', dst);
                alert("Document capture complete. The document is cropped and adjusted!"); // Confirmación final

                dst.delete(); M.delete(); srcTri.delete(); dstTri.delete();
            } else {
                alert("Could not detect a quadrilateral shape for the document.");  // No se detectó cuadrilátero
            }
        } else {
            alert("No document detected.");  // No se detectó documento
        }

        src.delete(); gray.delete(); edges.delete(); contours.delete(); hierarchy.delete(); approx.delete();
    }

    document.getElementById('captureButton').addEventListener('click', captureAndProcess);
    openCamera();
</script>

</body>
</html>
