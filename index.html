<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Improved Document Scanner</title>
    <style>
        #video, #canvasOutput {
            width: 100%;
            height: auto;
        }
        #captureButton {
            display: block;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 16px;
        }
        #error {
            color: red;
            text-align: center;
        }
    </style>
</head>
<body>

<h2>Document Scanner</h2>
<video id="video" autoplay playsinline></video>
<canvas id="canvasOutput"></canvas>
<button id="captureButton">Capture Document</button>
<p id="error"></p>

<script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
<script>
    async function openCamera() {
        try {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = stream;
            alert("Camera opened successfully");
        } catch (error) {
            document.getElementById('error').textContent = "Error accessing the camera: " + error.message;
            alert("Error accessing the camera: " + error.message);
        }
    }

    function captureAndProcess() {
        alert("Starting document capture process");

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvasOutput');
        const ctx = canvas.getContext('2d');
        const width = video.videoWidth;
        const height = video.videoHeight;

        canvas.width = width;
        canvas.height = height;

        ctx.drawImage(video, 0, 0, width, height);

        let src = cv.imread(canvas);
        let gray = new cv.Mat();
        let blurred = new cv.Mat();
        let edges = new cv.Mat();
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();

        // Convertir a escala de grises y desenfocar para mejorar la detección de bordes
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);
        
        // Aplicar umbral adaptable para mejor detección en diferentes condiciones de luz
        cv.adaptiveThreshold(blurred, edges, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);

        // Encontrar contornos
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let maxArea = 0;
        let largestContour;
        for (let i = 0; i < contours.size(); i++) {
            let contour = contours.get(i);
            let area = cv.contourArea(contour, false);
            if (area > maxArea) {
                maxArea = area;
                largestContour = contour;
            }
        }

        let approx = new cv.Mat();
        if (largestContour) {
            cv.approxPolyDP(largestContour, approx, 0.02 * cv.arcLength(largestContour, true), true);

            if (approx.rows === 4) {
                alert("Document detected, starting perspective transformation");

                const points = [];
                for (let i = 0; i < 4; i++) {
                    points.push({
                        x: approx.data32S[i * 2],
                        y: approx.data32S[i * 2 + 1]
                    });
                }

                points.sort((a, b) => a.y - b.y);
                const topPoints = points.slice(0, 2).sort((a, b) => a.x - b.x);
                const bottomPoints = points.slice(2).sort((a, b) => a.x - b.x);
                const sortedPoints = [...topPoints, ...bottomPoints];

                const srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    sortedPoints[0].x, sortedPoints[0].y,
                    sortedPoints[1].x, sortedPoints[1].y,
                    sortedPoints[2].x, sortedPoints[2].y,
                    sortedPoints[3].x, sortedPoints[3].y
                ]);
                const dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    0, 0, width, 0, width, height, 0, height
                ]);

                const M = cv.getPerspectiveTransform(srcTri, dstTri);
                const dst = new cv.Mat();
                cv.warpPerspective(src, dst, M, new cv.Size(width, height));

                // Aplicar binarización y ajuste de contraste para simular un escaneo
                let final = new cv.Mat();
                cv.cvtColor(dst, final, cv.COLOR_RGBA2GRAY);
                cv.adaptiveThreshold(final, final, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);

                cv.imshow('canvasOutput', final);
                alert("Document capture complete. The document is cropped, adjusted, and converted to black and white.");

                // Limpiar
                final.delete(); dst.delete(); M.delete(); srcTri.delete(); dstTri.delete();
            } else {
                alert("Could not detect a quadrilateral shape for the document.");
            }
        } else {
            alert("No document detected.");
        }

        src.delete(); gray.delete(); blurred.delete(); edges.delete(); contours.delete(); hierarchy.delete(); approx.delete();
    }

    document.getElementById('captureButton').addEventListener('click', captureAndProcess);
    openCamera();
</script>

</body>
</html>
